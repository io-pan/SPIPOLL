package org.reactnative.camera.tasks;

import com.google.android.gms.vision.face.Face;
import org.reactnative.frame.RNFrame;
import org.reactnative.frame.RNFrameFactory;
import org.iopan.motiondetector.MotionDetector;

import com.facebook.react.bridge.WritableMap;
import com.facebook.react.bridge.WritableArray;
import com.facebook.react.bridge.Arguments;
import android.graphics.Bitmap;
import android.graphics.Color;
import android.graphics.BitmapFactory;
import android.graphics.Matrix;

import com.google.zxing.BinaryBitmap;
import com.google.zxing.PlanarYUVLuminanceSource;
import  android.renderscript.Allocation;
import  android.renderscript.RenderScript;

import android.content.res.Resources;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import android.os.Environment;

import org.reactnative.camera.utils.RNFileUtils;
import android.util.Log;
import java.lang.Math;
import android.util.Base64;

public class MotionDetectorAsyncTask extends android.os.AsyncTask<Void, Void, WritableMap> {
  private byte[] mImageData;
  private int mWidth;
  private int mHeight;
  private int mViewWidth;
  private int mViewHeight;
  private float mDensity;
  private int mRotation;
  private MotionDetector mMotionDetector;
  private MotionDetectorAsyncTaskDelegate mDelegate;


  public MotionDetectorAsyncTask(
      MotionDetectorAsyncTaskDelegate delegate,
      MotionDetector motionDetector,
      byte[] imageData,
      int width,
      int height,
      int viewWidth,
      int viewHeight,
      float density,
      int rotation
  ) {
    mImageData = imageData;
    mWidth = width;
    mHeight = height;
    mViewWidth = viewWidth;
    mViewHeight = viewHeight;
    mDensity = density;
    mRotation = rotation;
    mDelegate = delegate;
    mMotionDetector = motionDetector;
  }

  @Override
  protected WritableMap doInBackground(Void... ignored) {
    if (mImageData==null || mViewWidth==0 || mViewHeight==0
      || isCancelled() || mDelegate == null || mMotionDetector == null || !mMotionDetector.isOperational()) {
      return null;
    }
    
    WritableMap retunValue  = Arguments.createMap();
    boolean motionDetected = false;
    WritableArray sampledPixels = Arguments.createArray();
    WritableArray motionPixels = Arguments.createArray();

    if(mImageData==null){
      retunValue.putString("error","mImageData NULL");
      return retunValue;
    }

    final int[] rgb = decodeYUV420SP(mImageData, mWidth, mHeight);
    Bitmap bitmap =  Bitmap.createBitmap(rgb, mWidth, mHeight, Bitmap.Config.ARGB_8888);
    if(bitmap==null){
      retunValue.putString("error","bitmap NULL");
      return retunValue;
    }

    bitmap = Bitmap.createScaledBitmap(
      rotateBitmap(bitmap,90),
      (int)((float)mViewWidth/mDensity), 
      (int)((float)mViewHeight/mDensity),
      false);

    int bitmapWidth = bitmap.getWidth();
    int bitmapHeight = bitmap.getHeight();

    // // Save preview as jpg file.
    String filname;
    filname = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM)+ "/test.jpg";
    try {
        // Prepare file output
        File imageFile = new File(filname);
        imageFile.createNewFile();
        FileOutputStream fOut = new FileOutputStream(imageFile);

        // Save byte array 
        // fOut.write(mImageData);
        fOut.write(toJpeg(bitmap, 70));
        fOut.flush();
        fOut.close();
        fOut=null;
        // Return file system URI
    

    } catch (Resources.NotFoundException e) {
        retunValue.putString("error","Documents directory of the app could not be found."+filname);
        return retunValue;
    } catch (IOException e) {
        retunValue.putString("error","An unknown I/O exception has occurred."+filname);
        return retunValue;
    }


    // Scan bitmap.
    // Maybe we shoud check if ViewSize as same ratio than previewImage
    int i = 0;
    int step = mMotionDetector.mSampleSize;
    int ratio = 1;//(int) Math.floor(bitmapHeight / mViewHeight);

    // Init previous data.
    if(mMotionDetector.mPreviousSampledRedValues == null){
      mMotionDetector.mPreviousSampledRedValues = new int[bitmapWidth*bitmapHeight];
    }

    //
    // Sample preview
    //

    Bitmap.Config conf = Bitmap.Config.ARGB_8888; // see other conf types
    Bitmap sampledPixelsFile = Bitmap.createBitmap(bitmapWidth, bitmapHeight, conf); // this creates a MUTABLE bitmap

    for ( int x = 0; x < bitmapWidth; x=x+step) {
      for ( int y = 0; y < bitmapHeight; y=y+step) {
        WritableMap pixel  = Arguments.createMap();
        int color = bitmap.getPixel(x, y);//bitmap.getPixel(x*ratio, y*ratio);
        String hex = Integer.toHexString(color);
        pixel.putString("color",hex.substring(2));
        pixel.putInt("x",x);
        pixel.putInt("y",y);
        sampledPixels.pushMap(pixel);

        // Draw sampled bitmap.
        for(int xs = 0; xs<step; xs++){
          if(x+xs < bitmapWidth){ // Ignore overlapping pixels.
            for(int ys = 0; ys<step; ys++){
              if( y+ys<bitmapHeight){ // Ignore overlapping pixels.
                sampledPixelsFile.setPixel(x+xs, y+ys, color);
              }
            }
          }
        }

        // // Check red value differences.
        // int redValue =  Color.red(color);
        // if(Math.abs(mMotionDetector.mPreviousSampledRedValues[i] - redValue) > mMotionDetector.mThreshold){
        //   motionDetected = true;
        //   WritableMap pixelMotion = Arguments.createMap();
        //   pixelMotion.putInt("x",x);
        //   pixelMotion.putInt("y",y);
        //   pixelMotion.putInt("score", 255-Math.abs(mMotionDetector.mPreviousSampledRedValues[i] - redValue));
        //   motionPixels.pushMap(pixelMotion);
        // }
        // mMotionDetector.mPreviousSampledRedValues[i] = Color.red(color);

        i++;
      }
    }

    // Encode sampled bitmap to base64 string.
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    sampledPixelsFile.compress(Bitmap.CompressFormat.PNG, 100, outputStream);
    String sampledBase64 = Base64.encodeToString(outputStream.toByteArray(), Base64.DEFAULT);

    // // Save sampled bitmap as file.
      // final File cacheDirectory = mScopedContext.getCacheDirectory();
      // String fileName = String.format("%s", new SimpleDateFormat("yyyyMMdd_HHmmss").format(new Date()));
          // if (type == MEDIA_TYPE_IMAGE) {
          //     fileName = String.format("IMG_%s.jpg", fileName);

    // FileOutputStream fOutputStream = null;
    // try {
    //     fOutputStream = new FileOutputStream(filname);
    //     sampledPixels.compress(Bitmap.CompressFormat.JPEG, 80, fOutputStream);
    //     fOutputStream.flush();
    //     fOutputStream.close();
    //     fOutputStream = null;
    //     // MediaStore.Images.Media.insertImage(getContentResolver(), file.getAbsolutePath(), file.getName(), file.getName());
    // } catch (Resources.NotFoundException e) {
    //   pixelDebug.putString("color","Documents directory of the app could not be found."+filname);
    //   sampledPixels.put(0,pixelDebug);
    //   return sampledPixels;
    // } catch (IOException e) {
    //   pixelDebug.putString("color","An unknown I/O exception has occurred."+filname);
    //   sampledPixels.put(0,pixelDebug);
    //   return sampledPixels;
    // }


    retunValue.putString("pixelRatio", ""+mDensity);
    retunValue.putString("threshold", "" + mMotionDetector.mThreshold);
    retunValue.putString("sample size", ""+mMotionDetector.mSampleSize);
    retunValue.putString("cap", mWidth+"x"+mHeight);
    retunValue.putString("view", mViewWidth+"x"+mViewHeight);
    retunValue.putString("bitmap", bitmapWidth+"x"+bitmapHeight);

    retunValue.putString("sampledBase64",sampledBase64);
    retunValue.putArray("sampled",sampledPixels);
    retunValue.putArray("motion",motionPixels);
    retunValue.putBoolean("motionDetected",motionDetected); 
    return retunValue;
  }

  @Override
  protected void onPostExecute(WritableMap motion) {
    super.onPostExecute(motion);

    if (motion == null) {
      mDelegate.onMotionDetectionError(mMotionDetector);
    } else {
      // if (motion.size() > 0) {
        mDelegate.onMotionDetected(motion, mWidth, mHeight, mRotation);
      // }
      mDelegate.onMotionDetectingTaskCompleted();
    }
  }

  public int[] decodeYUV420SP( byte[] yuv420sp, int width, int height) {   

    final int frameSize = width * height;   

    int rgb[]=new int[width*height];   
    for (int j = 0, yp = 0; j < height; j++) {   
      int uvp = frameSize + (j >> 1) * width, u = 0, v = 0;   
      for (int i = 0; i < width; i++, yp++) {   
        int y = (0xff & ((int) yuv420sp[yp])) - 16;   
        if (y < 0) y = 0;   
        if ((i & 1) == 0) {   
            v = (0xff & yuv420sp[uvp++]) - 128;   
            u = (0xff & yuv420sp[uvp++]) - 128;   
        }   

        int y1192 = 1192 * y;   
        int r = (y1192 + 1634 * v);   
        int g = (y1192 - 833 * v - 400 * u);   
        int b = (y1192 + 2066 * u);   

        if (r < 0) r = 0; else if (r > 262143) r = 262143;   
        if (g < 0) g = 0; else if (g > 262143) g = 262143;   
        if (b < 0) b = 0; else if (b > 262143) b = 262143;   

        rgb[yp] = 0xff000000 | ((r << 6) & 0xff0000) | ((g >> 2) & 0xff00) | ((b >> 10) & 0xff);   
      }   
    }   
    return rgb;   
  } 



  private static byte[] toJpeg(Bitmap bitmap, int quality) throws OutOfMemoryError {
      ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
      bitmap.compress(Bitmap.CompressFormat.JPEG, quality, outputStream);

      try {
          return outputStream.toByteArray();
      } finally {
          try {
              outputStream.close();
          } catch (IOException e) {
              Log.e("IOIO", "problem compressing jpeg", e);
          }
      }
  }

  public static Bitmap rotateBitmap(Bitmap source, float angle){
        Matrix matrix = new Matrix();
        matrix.postRotate(angle);
        return Bitmap.createBitmap(source, 0, 0, source.getWidth(), source.getHeight(), matrix, true);
  }
}

